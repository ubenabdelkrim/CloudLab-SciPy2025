{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import lithops\n",
    "import pandas as pd\n",
    "from dataplug import CloudObject\n",
    "\n",
    "from dataplug.formats.genomics.fasta import FASTA, partition_chunks_strategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ” AWS Credentials Configuration\n",
    "\n",
    "There are two main ways to configure your AWS credentials:\n",
    "\n",
    "---\n",
    "\n",
    "#### âœ… Option 1: (Recommended) Use AWS CLI profiles\n",
    "\n",
    "You can securely configure your credentials using the AWS CLI:\n",
    "\n",
    "Run the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "aws configure\n",
    "```\n",
    "\n",
    "âœ… This is the **safest and most recommended approach**, especially for production environments or shared projects.\n",
    "\n",
    "---\n",
    "\n",
    "#### âš ï¸ Option 2: (Less secure) Set credentials in code\n",
    "\n",
    "For quick experiments or in isolated environments, you can manually set the environment variables in this notebook:\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AWS_ACCESS_KEY_ID\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"AWS_SECRET_ACCESS_KEY\"\n",
    "```\n",
    "\n",
    "> âš ï¸ **IMPORTANT**: Never expose your credentials in source code or public repositories.  \n",
    "> This method should only be used for temporary testing and never in production.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš™ï¸ Preprocessing a FASTA File from S3 with Lithops\n",
    "\n",
    "The following code loads a FASTA file stored in an S3 bucket using `CloudObject` and preprocesses it in **4 parallel jobs** by dividing the file into chunks.\n",
    "\n",
    "```python\n",
    "co = CloudObject.from_s3(\n",
    "    FASTA, \n",
    "    \"s3://dnastack-covid-19-sra-data/PacBio/fasta/SRR16804994/SRR16804994.fasta\"\n",
    ")\n",
    "\n",
    "# Perform preprocessing in 4 parallel jobs (chunk size = total size / 4)\n",
    "parallel_config = {\"verbose\": 10}\n",
    "chunk_size = math.ceil(co.size / 4)\n",
    "co.preprocess(parallel_config=parallel_config, chunk_size=chunk_size)\n",
    "```\n",
    "\n",
    "- `CloudObject.from_s3(...)`: Loads the remote FASTA file as a Lithops CloudObject.\n",
    "- `co.size`: Retrieves the size of the file in bytes.\n",
    "- `chunk_size`: Determines the number of bytes each parallel job will process.\n",
    "- `preprocess(...)`: Splits and processes the file using **4 parallel workers**, improving performance for large datasets.\n",
    "\n",
    "> â„¹ï¸ You can adjust the number of parallel jobs by modifying the divisor used in the `chunk_size` calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = CloudObject.from_s3(FASTA, \"s3://dnastack-covid-19-sra-data/PacBio/fasta/SRR16804994/SRR16804994.fasta\")\n",
    "\n",
    "# Perform preprocessing in 4 parallel jobs (chunk size = total size / 4)\n",
    "parallel_config = {\"verbose\": 10}\n",
    "chunk_size = math.ceil(co.size / 4)\n",
    "co.preprocess(parallel_config=parallel_config, chunk_size=chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Inspecting and Partitioning the FASTA File\n",
    "\n",
    "After loading the FASTA file as a `CloudObject`, we can inspect its metadata and split it into multiple slices for parallel processing.\n",
    "\n",
    "```python\n",
    "print(f\"FASTA file has {co.attributes.num_sequences} sequences\")\n",
    "\n",
    "data_slices = co.partition(partition_chunks_strategy, num_chunks=8)\n",
    "```\n",
    "\n",
    "- `co.attributes.num_sequences`: Returns the number of sequences found in the FASTA file.\n",
    "- `partition(...)`: Divides the file into chunks using the `partition_chunks_strategy` and the specified number of partitions (`num_chunks=8`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file has 1 sequences\n"
     ]
    }
   ],
   "source": [
    "print(f\"FASTA file has {co.attributes.num_sequences} sequences\")\n",
    "data_slices = co.partition(partition_chunks_strategy, num_chunks=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'>SRR16804994\\nNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGGCTGCATGCTTAGTGCACTCACGCAGTATAATTAATAACTAATTACTGTCGTTGACAGGACACGAGTAACTCGTCTATCTTCTGCAGGCTGCTTACGGTTTCGTCCGTTTTGCAGCCGATTATCAGCACATCTAGGTTTTGTCCGGGTGTGACCGAAAGGTAAGATGGAGAGCCTTGTCCCTGGTTTCAACGAGAAAACACACGTCCAACTCAGTTTGCCTGTTTTACAGGTTCGCGACGTGCTCGTACGTGGCTTTGGAGACTCCGTGGAGGAGGTCTTATCAGAGGCACGTCAACATCTTAAAGATGGCACTTGTGGCTTAGTAGAAGTTGAAAAAGGCGTTTTGCCTCAACTTGAACAGCCCTATGTGTTCATCAAACGTTCGGATGCTCGAACTGTACCTCATGGTCATGTTATGGTTGAGCTGGTAGCAGAACTCGAAGGCATTCAGTACGGTCGTAGTGGTGAGACACTTGGTGTCCTTGTCCCTCATGTGGGCGAAATACCAGTGGCTTACCGCAAGGTTCTTCTTCGTAAGAACGGTAATAAAGGAGCTGGTGGCCATAGTTACGGCGCCGATCTAAAGTCATTTGACTTAGGCGACGAGCTTGGCACTGATCCTTATGAAGATTTTCAAGAAAACTGGAACACTAAACATAGCAGTGGTGTTACCCGTGAACTCATGCGTGAGCTTAACGGAGGGGCATACACTCGCTATGTCGATAACAACTTCTGTGGCCCTGATGGCTACCCTCTTGAGTGCATTAAAGACCTTCTAGCACGTGCTGGTAAAGCTTCATGCACTTTGTCCGAACAACTGGACTTTATTGACACTAAGAGGGGTGTATACTGCTGCCGTGAACATGAGCATGAAATTGCTTGGTACACGGAACGTTCTGAAAAGAGCTATGAATTGCAGACACCTTTTGAAATTAAATTGGCAAAGAAATTTGACACCTTCAATGGGGAATGTCCAAATTTTGTATTTCCCTTAAATTCCATAATCAAGACTATTCAACCAAGGGTTGAAAAGAAAAAGCTTGATGGCTTTATGGGTAGAATTCGATCTGTCTATCCAGTTGCGTCACCAAATGAATGCAACCAAATGTGCCTTTCAACTCTCATGAAGTGTGATCATTGTGGTGAAACTTCATGGCAGACGGGCGATTTTGTTAAAGCCACTTGCGAATTTTGTGGCACTGAGAATTTGACTAAAGAAGGTGCCACTACTTGTGGTTACTTACCCCAAAATGCTGTTGTTAAAATTTATTGTCCAGCATGTCACAATTCAGAAGTAGGACCTGAGCATAGTCTTGCCGAATACCATAATGAATCTGGCTTGAAAACCATTCTTCGTAAGGGTGGTCGCACTATTGCCTTTGGAGGCTGTGTGTTCTCTTATGTTGGTTGCCATAACAAGTGTGCCTATTGGGTTCCACGTGCTAGCGCTAACATAGGTTGTAACCATACAGGTGTTGTTGGAGAAGGTTCCGAAGGTCTTAATGACAACCTTCTTGAAATACTCCAAAAAGAGAAAGTCAACATCAATATTGTTGGTGACTTTAAACTTAATGAAGAGATCGCCATTATTTTGGCATCTTTTTCTGCTTCCACAAGTGCTTTTGTGGAAACTGTGAAAGGTTTGGATTATAAAGCATTCAAACAAATTGTTGAATCCTGTGGTAATTTTAAAGTTACAAAAGGAAAAGCTAAAAAAGGTGCCTGGAATATTGGTGAACAGAAATCAATACTGAGTCCTCTTTATGCATTTGCATCAGAGGCTGCTCGTGTTGTACGATCAATTTTCTCCCGCACTCTTGAAACTGCTCAAAATTCTGTGCGTGTTTTACAGAAGGCCGCTATAACAATACTAGATGGAATTTCACAGTATTCACTGAGACTCATTGATGCTATGATGTTCACATCTGATTTGGCTACTAACAATCTAGTTGTAATGGCCTACATTACAGGTGGTGTTGTTCAGTTGACTTCGCAGTGGCTAACTAACATCTTTGGCACTGTTTATGAAAAACTCAAACCCGTCCTTGATTGGCTTGAAGAGAAGTTTAAGGAAGGTGTAGAGTTTCTTAGAGACGGTTGGGAAATTGTTAAATTTATCTCAACCTGTGCTTGTGAAATTGTCGGTGGACAAATTGTCACCTGTGCAAAGGAAATTAAGGAGAGTGTTCAGACATTCTTTAAGCTTGTAAATAAATTTTTGGCTTTGTGTGCTGACTCTATCATTATTGGTGGAGCTAAACTTAAAGCCTTGAATTTAGGTGAAACATTTGTCACGCACTCAAAGGGATTGTACAGAAAGTGTGTTAAATCCAGAGAAGAAACTGGCCTACTCATGCCTCTAAAAGCCCCAAAAGAAATTATCTTCTTAGAGGGAGAAACACTTCCCACAGAAGTGTTAACAGAGGAAGTTGTCTTGAAAACTGGTGATTTACAACCATTAGAACAACCTACTAGTGAAGCTGTTGAAGCTCCATTGGTTGGTACACCAGTTTGTATTAACGGGCTTATGTTGCTCGAAATCAAAGACACAGAAAAGTACTGTGCCCTTGCACCTAATATGATGGTAACAAACAATACCTTCACACTCAAAGGCGGTGCACCAACAAAGGTTACTTTTGGTGATGACACTGTGATAGAAGTGCAAGGTTACAAGAGTGTGAATATCACTTTTGAACTTGATGAAAGGATTGATAAAGTACTTAATGAGAAGTGCTCTGCCTATACAGTTGAACTCGGTACAGAAGTAAATGAGTTCGCCTGTGTTGTGGCAGATGCTGTCATAAAAACTTTGCAACCAGTATCTGAATTACTTACACCACTGGGCATTGATTTAGATGAGTGGAGTATGGCTACATACTACTTATTTGATGAGTCTGGTGAGTTTAAATTGGCTTCACATATGTATTGTTCTTTTTACCCTCCAGATGAGGATGAAGAAGAAGGTGATTGTGAAGAAGAAGAGTTTGAGCCATCAACTCAATATGAGTATGGTACTGAAGATGATTACCAAGGTAAACCTTTGGAATTTGGTGCCACTTCTGCTGCTCTTCAACCTGAAGAAGAGCAAGAAGAAGATTGGTTAGATGATGATAGTCAACAAACTGTTGGTCAACAAGACGGCAGTGAGGACAATCAGACAACTACTATTCAAACAATTGTTGAGGTTCAACCTCAATTAGAGATGGAACTTACACCAGTTGTTCAGACTATTGAAGTGAATAGTTTTAGTGGTTATTTAAAACTTACTGACAATGTATACATTAAAAATGCAGACATTGTGGAAGAAGCTAAAAAGGTAAAACCAACAGTGGTTGTTAATGCAGCCAATGTTTACCTTAAACATGGAGGAGGTGTTGCAGGAGCCTTAAATAAGGCTACTAACAATGCCATGCAAGTTGAATCTGATGATTACATAGCTACTAATGGACCACTTAAAGTGGGTGGTAGTTGTGTTTTAAGCGGACACAATCTTGCTAAACACTGTCTTCATGTTGTCGGCCCAAATGTTAACAAAGGTGAAGACATTCAACTTCTTAAGAGTGCTTATGAAAATTTTAATCAGCACGAAGTTCTACTTGCACCATTATTATCAGCTGGTATTT'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slices[0].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§¬ Processing FASTA Partitions\n",
    "\n",
    "The following function processes a partition (chunk) of a FASTA file and extracts useful statistics such as the number of sequences and their length distribution.\n",
    "\n",
    "#### ðŸ” What this function does:\n",
    "\n",
    "- Retrieves and decodes the content of a FASTA chunk.\n",
    "- Iterates through the lines and accumulates DNA sequence lengths.\n",
    "- When a new sequence header (`>`) is encountered, it stores the length of the previous sequence.\n",
    "- After processing, it returns:\n",
    "  - `record_count`: Number of sequences found.\n",
    "  - `min_length`: Length of the shortest sequence.\n",
    "  - `max_length`: Length of the longest sequence.\n",
    "\n",
    "> â„¹ï¸ This function can be executed in parallel across all partitions to compute statistics efficiently over large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fasta_partition(fasta_chunk):\n",
    "    lines = fasta_chunk.get().decode('utf-8').split('\\n')\n",
    "    read_lengths = []\n",
    "    sequence = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('>'):\n",
    "            if sequence:\n",
    "                read_lengths.append(len(sequence))\n",
    "                sequence = \"\"\n",
    "        else:\n",
    "            sequence += line.strip()\n",
    "\n",
    "    if sequence:\n",
    "        read_lengths.append(len(sequence))\n",
    "\n",
    "    if not read_lengths:\n",
    "        return {\n",
    "            \"record_count\": 0,\n",
    "            \"min_length\": None,\n",
    "            \"max_length\": None\n",
    "        }\n",
    "\n",
    "    record_count = len(read_lengths)\n",
    "    min_length = min(read_lengths)\n",
    "    max_length = max(read_lengths)\n",
    "\n",
    "    return {\n",
    "        \"record_count\": record_count,\n",
    "        \"min_length\": min_length,\n",
    "        \"max_length\": max_length\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš¡ Parallel Execution with Lithops and Dataplug\n",
    "\n",
    "Using `lithops.FunctionExecutor`, we can easily launch parallel computations over the data partitions produced by Dataplug.\n",
    "\n",
    "```python\n",
    "with lithops.FunctionExecutor() as executor:\n",
    "    futures = executor.map(process_fasta_partition, data_slices)\n",
    "    results = executor.get_result(futures)\n",
    "```\n",
    "\n",
    "#### ðŸš€ Highlights:\n",
    "\n",
    "- **Seamless integration** between **Dataplug** and **Lithops**:  \n",
    "  The `data_slices` returned by `co.partition(...)` are directly compatible with `executor.map(...)`, making it easy to scale up processing.\n",
    "  \n",
    "- **Serverless execution**:  \n",
    "  Each partition is processed independently and in parallel, leveraging cloud functions without the need to manage infrastructure.\n",
    "\n",
    "- `executor.map(...)`: Applies the `process_fasta_partition` function to each partition.\n",
    "- `executor.get_result(...)`: Collects the results once all functions have completed.\n",
    "\n",
    "> âœ… This tight integration enables effortless scaling for processing large datasets stored in S3 or other backends â€” with just a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 13:41:18,639 [INFO] config.py:146 -- Lithops v3.5.2.dev0 - Python3.10\n",
      "2025-03-28 13:41:18,640 [DEBUG] config.py:107 -- Loading configuration from the cloud\n",
      "2025-03-28 13:41:19,016 [DEBUG] config.py:186 -- Loading Serverless backend module: aws_lambda\n",
      "2025-03-28 13:41:19,024 [DEBUG] config.py:226 -- Loading Storage backend module: aws_s3\n",
      "2025-03-28 13:41:19,029 [DEBUG] aws_s3.py:36 -- Creating AWS S3 Client\n",
      "2025-03-28 13:41:19,188 [INFO] aws_s3.py:59 -- S3 client created - Region: us-east-1\n",
      "2025-03-28 13:41:19,234 [DEBUG] aws_lambda.py:53 -- Creating AWS Lambda client\n",
      "2025-03-28 13:41:19,579 [INFO] aws_lambda.py:97 -- AWS Lambda client created - Region: us-east-1\n",
      "2025-03-28 13:41:19,583 [DEBUG] invokers.py:105 -- ExecutorID a08781-0 - Invoker initialized. Max workers: 1000\n",
      "2025-03-28 13:41:19,584 [DEBUG] invokers.py:308 -- ExecutorID a08781-0 - Serverless invoker created\n",
      "2025-03-28 13:41:19,736 [DEBUG] executors.py:164 -- Function executor for aws_lambda created with ID: a08781-0\n",
      "2025-03-28 13:41:19,737 [INFO] invokers.py:119 -- ExecutorID a08781-0 | JobID M000 - Selected Runtime: runtime-ubenabdelkrim-6683a993-ab22-42c5-a3f3-79f14d7c09da:660fc9d3-cb33-467a-8193-7c52ff14bf04-amd64 - 256MB\n",
      "2025-03-28 13:41:19,739 [DEBUG] storage.py:476 -- Runtime metadata found in local disk cache\n",
      "2025-03-28 13:41:19,741 [DEBUG] job.py:242 -- ExecutorID a08781-0 | JobID M000 - Serializing function and data\n",
      "2025-03-28 13:41:19,761 [DEBUG] serialize.py:75 -- Referenced Modules: dataplug, io, shutil, __main__\n",
      "2025-03-28 13:41:19,762 [DEBUG] module_dependency.py:109 -- Module 'dataplug' is already installed in the runtime, skipping\n",
      "2025-03-28 13:41:19,764 [DEBUG] module_dependency.py:109 -- Module 'io' is already installed in the runtime, skipping\n",
      "2025-03-28 13:41:19,765 [DEBUG] module_dependency.py:109 -- Module 'shutil' is already installed in the runtime, skipping\n",
      "2025-03-28 13:41:19,768 [DEBUG] serialize.py:120 -- Modules to transmit: None\n",
      "2025-03-28 13:41:19,770 [DEBUG] job.py:276 -- ExecutorID a08781-0 | JobID M000 - Uploading function and modules to the storage backend\n",
      "2025-03-28 13:41:19,804 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/a08781-0/70391859748ae62caa2f54eaedf11566.func.pickle - Size: 929.0B - OK\n",
      "2025-03-28 13:41:19,805 [DEBUG] job.py:316 -- ExecutorID a08781-0 | JobID M000 - Data per activation is < 8.0KiB. Passing data through invocation payload\n",
      "2025-03-28 13:41:19,807 [INFO] invokers.py:187 -- ExecutorID a08781-0 | JobID M000 - Starting function invocation: process_fasta_partition() - Total: 8 activations\n",
      "2025-03-28 13:41:19,808 [DEBUG] metrics.py:56 -- Sending metric 'job_total_calls' with value 8 and labels {'job_id': 'a08781-0-M000', 'function_name': 'process_fasta_partition'} to https://metrics.pyrun.cloud/metrics\n",
      "2025-03-28 13:41:21,382 [DEBUG] metrics.py:70 -- Metric sent successfully: 204, \n",
      "2025-03-28 13:41:21,384 [DEBUG] metrics.py:56 -- Sending metric 'job_runtime_memory' with value 256 and labels {'job_id': 'a08781-0-M000', 'function_name': 'process_fasta_partition'} to https://metrics.pyrun.cloud/metrics\n",
      "2025-03-28 13:41:21,488 [DEBUG] metrics.py:70 -- Metric sent successfully: 204, \n",
      "2025-03-28 13:41:21,492 [DEBUG] invokers.py:213 -- ExecutorID a08781-0 | JobID M000 - Worker processes: 1 - Chunksize: 1\n",
      "2025-03-28 13:41:21,495 [DEBUG] invokers.py:317 -- ExecutorID a08781-0 - Async invoker 0 started\n",
      "2025-03-28 13:41:21,498 [DEBUG] invokers.py:446 -- ExecutorID a08781-0 | JobID M000 - Free workers: 1000 - Going to run 8 activations in 8 workers\n",
      "2025-03-28 13:41:21,497 [DEBUG] invokers.py:317 -- ExecutorID a08781-0 - Async invoker 1 started\n",
      "2025-03-28 13:41:21,536 [INFO] invokers.py:226 -- ExecutorID a08781-0 | JobID M000 - View execution logs at /tmp/lithops-root/logs/a08781-0-M000.log\n",
      "2025-03-28 13:41:21,544 [DEBUG] monitor.py:429 -- ExecutorID a08781-0 - Starting Storage job monitor\n",
      "2025-03-28 13:41:21,545 [INFO] executors.py:507 -- ExecutorID a08781-0 - Getting results from 8 function activations\n",
      "2025-03-28 13:41:21,565 [INFO] wait.py:101 -- ExecutorID a08781-0 - Waiting for 8 function activations to complete\n",
      "2025-03-28 13:41:21,613 [DEBUG] invokers.py:389 -- ExecutorID a08781-0 | JobID M000 - Calls 00000 invoked (0.113s) - Activation ID: c2ab8141-c343-4692-aa68-e44d7240525d\n",
      "2025-03-28 13:41:21,632 [DEBUG] invokers.py:389 -- ExecutorID a08781-0 | JobID M000 - Calls 00001 invoked (0.128s) - Activation ID: f751fb66-9fa2-45a7-9af1-f1326c6e7b0b\n",
      "2025-03-28 13:41:21,667 [DEBUG] invokers.py:389 -- ExecutorID a08781-0 | JobID M000 - Calls 00004 invoked (0.150s) - Activation ID: 1c7db815-19fd-4c1b-bff0-bbe91f71532e\n",
      "2025-03-28 13:41:21,668 [DEBUG] invokers.py:389 -- ExecutorID a08781-0 | JobID M000 - Calls 00006 invoked (0.137s) - Activation ID: 68b040c4-03ce-49a1-9363-a125ef3485ae\n",
      "2025-03-28 13:41:21,669 [DEBUG] invokers.py:389 -- ExecutorID a08781-0 | JobID M000 - Calls 00002 invoked (0.163s) - Activation ID: 74059203-2dc9-4504-929e-c29b85f34288\n",
      "2025-03-28 13:41:21,672 [DEBUG] invokers.py:389 -- ExecutorID a08781-0 | JobID M000 - Calls 00007 invoked (0.138s) - Activation ID: 506967f4-eebd-4242-bd63-14434e102883\n",
      "2025-03-28 13:41:21,678 [DEBUG] invokers.py:389 -- ExecutorID a08781-0 | JobID M000 - Calls 00005 invoked (0.150s) - Activation ID: d23df6e7-d129-4725-9aea-cac04c9cbe1d\n",
      "2025-03-28 13:41:21,685 [DEBUG] invokers.py:389 -- ExecutorID a08781-0 | JobID M000 - Calls 00003 invoked (0.174s) - Activation ID: a9d234c8-09e7-474b-a54b-a25bf7e52dba\n",
      "2025-03-28 13:41:23,754 [DEBUG] monitor.py:144 -- ExecutorID a08781-0 - Pending: 8 - Running: 0 - Done: 0\n",
      "2025-03-28 13:41:25,875 [DEBUG] monitor.py:144 -- ExecutorID a08781-0 - Pending: 0 - Running: 8 - Done: 0\n",
      "2025-03-28 13:41:38,331 [DEBUG] monitor.py:144 -- ExecutorID a08781-0 - Pending: 0 - Running: 1 - Done: 7\n",
      "2025-03-28 13:41:38,595 [DEBUG] future.py:229 -- ExecutorID a08781-0 | JobID M000 - Got status from call 00000 - Activation ID: c2ab8141-c343-4692-aa68-e44d7240525d - Time: 13.76 seconds\n",
      "2025-03-28 13:41:38,597 [DEBUG] future.py:286 -- ExecutorID a08781-0 | JobID M000 - Got output from call 00000 - Activation ID: c2ab8141-c343-4692-aa68-e44d7240525d\n",
      "2025-03-28 13:41:38,598 [DEBUG] future.py:229 -- ExecutorID a08781-0 | JobID M000 - Got status from call 00002 - Activation ID: 74059203-2dc9-4504-929e-c29b85f34288 - Time: 13.35 seconds\n",
      "2025-03-28 13:41:38,595 [DEBUG] future.py:229 -- ExecutorID a08781-0 | JobID M000 - Got status from call 00001 - Activation ID: f751fb66-9fa2-45a7-9af1-f1326c6e7b0b - Time: 14.00 seconds\n",
      "2025-03-28 13:41:38,608 [DEBUG] future.py:286 -- ExecutorID a08781-0 | JobID M000 - Got output from call 00001 - Activation ID: f751fb66-9fa2-45a7-9af1-f1326c6e7b0b\n",
      "2025-03-28 13:41:38,605 [DEBUG] future.py:229 -- ExecutorID a08781-0 | JobID M000 - Got status from call 00006 - Activation ID: 68b040c4-03ce-49a1-9363-a125ef3485ae - Time: 13.26 seconds\n",
      "2025-03-28 13:41:38,611 [DEBUG] future.py:286 -- ExecutorID a08781-0 | JobID M000 - Got output from call 00006 - Activation ID: 68b040c4-03ce-49a1-9363-a125ef3485ae\n",
      "2025-03-28 13:41:38,607 [DEBUG] future.py:229 -- ExecutorID a08781-0 | JobID M000 - Got status from call 00004 - Activation ID: 1c7db815-19fd-4c1b-bff0-bbe91f71532e - Time: 14.27 seconds\n",
      "2025-03-28 13:41:38,608 [DEBUG] future.py:229 -- ExecutorID a08781-0 | JobID M000 - Got status from call 00007 - Activation ID: 506967f4-eebd-4242-bd63-14434e102883 - Time: 13.33 seconds\n",
      "2025-03-28 13:41:38,600 [DEBUG] future.py:229 -- ExecutorID a08781-0 | JobID M000 - Got status from call 00003 - Activation ID: a9d234c8-09e7-474b-a54b-a25bf7e52dba - Time: 13.34 seconds\n",
      "2025-03-28 13:41:38,605 [DEBUG] future.py:286 -- ExecutorID a08781-0 | JobID M000 - Got output from call 00002 - Activation ID: 74059203-2dc9-4504-929e-c29b85f34288\n",
      "2025-03-28 13:41:38,617 [DEBUG] future.py:286 -- ExecutorID a08781-0 | JobID M000 - Got output from call 00004 - Activation ID: 1c7db815-19fd-4c1b-bff0-bbe91f71532e\n",
      "2025-03-28 13:41:38,620 [DEBUG] future.py:286 -- ExecutorID a08781-0 | JobID M000 - Got output from call 00007 - Activation ID: 506967f4-eebd-4242-bd63-14434e102883\n",
      "2025-03-28 13:41:38,622 [DEBUG] future.py:286 -- ExecutorID a08781-0 | JobID M000 - Got output from call 00003 - Activation ID: a9d234c8-09e7-474b-a54b-a25bf7e52dba\n",
      "2025-03-28 13:41:38,791 [DEBUG] monitor.py:144 -- ExecutorID a08781-0 - Pending: 0 - Running: 0 - Done: 8\n",
      "2025-03-28 13:41:38,792 [DEBUG] monitor.py:457 -- ExecutorID a08781-0 - Storage job monitor finished\n",
      "2025-03-28 13:41:39,637 [DEBUG] future.py:229 -- ExecutorID a08781-0 | JobID M000 - Got status from call 00005 - Activation ID: d23df6e7-d129-4725-9aea-cac04c9cbe1d - Time: 14.18 seconds\n",
      "2025-03-28 13:41:39,639 [DEBUG] future.py:286 -- ExecutorID a08781-0 | JobID M000 - Got output from call 00005 - Activation ID: d23df6e7-d129-4725-9aea-cac04c9cbe1d\n",
      "2025-03-28 13:41:39,641 [INFO] executors.py:631 -- ExecutorID a08781-0 - Cleaning temporary data\n",
      "2025-03-28 13:41:39,644 [DEBUG] executors.py:532 -- ExecutorID a08781-0 - Finished getting results\n",
      "2025-03-28 13:41:39,645 [DEBUG] invokers.py:344 -- ExecutorID a08781-0 - Stopping async invokers\n",
      "2025-03-28 13:41:39,651 [DEBUG] invokers.py:331 -- ExecutorID a08781-0 - Async invoker 0 finished\n",
      "2025-03-28 13:41:39,651 [DEBUG] invokers.py:331 -- ExecutorID a08781-0 - Async invoker 1 finished\n"
     ]
    }
   ],
   "source": [
    "with lithops.FunctionExecutor() as executor:\n",
    "    futures = executor.map(process_fasta_partition, data_slices)\n",
    "    results = executor.get_result(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 1 results:\n",
      "  Min Length: 3725\n",
      "  Max Length: 3725\n",
      "  Record Count: 1\n",
      "Partition 2 results:\n",
      "  Min Length: 3738\n",
      "  Max Length: 3738\n",
      "  Record Count: 1\n",
      "Partition 3 results:\n",
      "  Min Length: 3738\n",
      "  Max Length: 3738\n",
      "  Record Count: 1\n",
      "Partition 4 results:\n",
      "  Min Length: 3738\n",
      "  Max Length: 3738\n",
      "  Record Count: 1\n",
      "Partition 5 results:\n",
      "  Min Length: 3738\n",
      "  Max Length: 3738\n",
      "  Record Count: 1\n",
      "Partition 6 results:\n",
      "  Min Length: 3738\n",
      "  Max Length: 3738\n",
      "  Record Count: 1\n",
      "Partition 7 results:\n",
      "  Min Length: 3738\n",
      "  Max Length: 3738\n",
      "  Record Count: 1\n",
      "Partition 8 results:\n",
      "  Min Length: 3737\n",
      "  Max Length: 3737\n",
      "  Record Count: 1\n",
      "Total record count from all partitions: 8\n"
     ]
    }
   ],
   "source": [
    "total_records = 0\n",
    "for idx, res in enumerate(results):\n",
    "    print(f\"Partition {idx + 1} results:\")\n",
    "    print(f\"  Min Length: {res['min_length']}\")\n",
    "    print(f\"  Max Length: {res['max_length']}\")\n",
    "    print(f\"  Record Count: {res['record_count']}\")\n",
    "    total_records += res['record_count']\n",
    "\n",
    "print(f\"Total record count from all partitions: {total_records}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
